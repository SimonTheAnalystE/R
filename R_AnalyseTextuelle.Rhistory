library(R.temis)
library(tidyverse)
library(tm)
library(RColorBrewer)
library(wordcloud)
setwd("/Users/simonhoestlandt/Documents/PPA/PPA M2/R/PARTIEL2")
Corpus<-import_corpus("analyse textuelle_chatGPT", format="txt", language="fr")
MetaD<-read.csv2("Metadata_chatGPT.csv", header=TRUE)
corpus<-set_corpus_variables(Corpus, MetaD)
corpus
#Nous retrouvons donc bien les dix textes qui composeront notre corpus pour la suite de nos analyses.
#À présent, nous allons nous pencher sur le nettoyage de ces textes.
corpus <-tm_map(corpus, removeNumbers)
corpus <-tm_map(corpus, removePunctuation)
corpus <-tm_map(corpus, stripWhitespace)
corpus <-tm_map(corpus, content_transformer(tolower))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
corpus
inspect(corpus)
corpus <- tm_map(corpus, toSpace, "/")
corpus <- tm_map(corpus, toSpace, "@")
corpus <- tm_map(corpus, toSpace, "\\|")
corpus <- tm_map(corpus, toSpace, "’")
inspect(corpus)
corpus <-tm_map(corpus, removeWords, stopwords("french"))
corpus_racine <-tm_map(corpus, stemDocument, language="french")
#Maintenant, que nous avons nettoyé nos textes et créé un corpus racine, nous allons les inspecter afin de comparer notre corpus initial et celui comportant les mots racine.
inspect(corpus) & inspect(corpus_racine)
inspect(corpus)
#Nous remarquons qu'il y a des différences entre le corpus initial et le corpus racinisé. Par exemple, pour le premier texte comportait 6920 mots contre 5589 pour le corpus racinisé.
# Nous n'avons pas perdu de textes avec 10 textes pour chaque corpus.
# Nous attaquons le découpage de nos différents textes.
corpus<-split_documents(corpus, 3)
corpus_racine<-split_documents(corpus, 3)
corpus
corpus_racine
#Nous avons découpé nos documents et regardons à présent la sparsity. Pour confirmer que notre choix de découpage en trois est bon.
dtm<-build_dtm(corpus)
dtm_racine<-build_dtm(corpus_racine)
dtm
dtm_racine
#Sur nos deux corpus les clusters seront homogènes car la sparsity est suppérieure à 60%. Ici 98%
#Nous mettons ensuite en place des dictionnaires pour nos deux corpus en enlevant les mots vides.
dico<- dictionary(dtm, remove_stopwords=T)
dico_racine<- dictionary(dtm_racine, remove_stopwords=T)
View(dico)
View(dico_racine)
corpus2 <-tm_map(corpus, removeWords, c("plus", "ainsi", "si", "alors", "tout", "donc", "entre", "autre", "aussi", "encore", "lorsqu'", "or", "ceux", "enfin", "sous", "tant", "tous", "tout", "etc", "outre", "ça", "ni", "comment", "comme", "peut", "être"))
dtm2<-build_dtm(corpus2)
corpus_racine2 <-tm_map(corpus_racine, removeWords, c("plus", "ainsi", "si", "alors", "tout", "donc", "entre", "autre", "aussi", "encore", "lorsqu'", "or", "ceux", "enfin", "sous", "tant", "tous", "tout", "etc", "outre", "ça", "ni", "comment", "comme", "peut", "être"))
dtm_racine2<-build_dtm(corpus_racine2)
View(sapply(corpus2,as.character))
#Dans nos précédentes actions, nous avons identifié les mots qui auraient pu apparaitre dans un nuage de mot sans réelle utilité. Par exemple, nous avons supprimé les "plus", "ainsi", "tout","donc", "entre",etc.
#Maintenant, nous allons nous essayer de comprendre les mots les plus fréquents, les avantages, les freins, les biais, les limites et les usages attendus de l’intelligence artificielle générative.
frequent_terms(corpus2)
TermDocumentMatrix(corpus2)
dtm3<-TermDocumentMatrix(corpus2)
m<-as.matrix(dtm3)
v<- sort(rowSums(m),decreasing=TRUE)
d<- data.frame(word = names(v),freq=v)
#Les dix mots les plus cités dans notre corpus sont :
head(d, 10)
#Nous allons les résumer sous forme de graphique rose car c'est beau et visuel.
barplot(d[1:10,]$freq, las = 2,
names.arg = d[1:10,]$word,
col ="pink", main ="Most frequent words", ylab = "Word frequencies")
#Le terme "belotti" attire notre attention, nous allons observer le contexte de citation.
dtmX <-build_dtm(corpus2)
concordances(corpus2, dtmX, "bellotti")
#Marianne Bellotti est une scientifique assez active dans le monde de l'IA.
#À présent, nous pouvons former un nuage de mot présentant les mots les plus fréquents dans le corpus texte
cloud<- word_cloud(dtm2, col=1:10, n=100, min.freq=4)
frequent_terms(dtm2)
#Nous retrouvons ci-dessus les mots les plus fréquents présentés dans le nuage de mot.
#Basé sur les mots les plus fréquents dans notre corpus de textes, nous allons à présent créer un réseau sémantique pour pouvoir analyser les différentes associations avec ces derniers.
cooc_terms(dtm2, "chatgpt")
#Nous observons des liens significatifs dans les co-occurrences avec le terme "chatgpt"
#Parmi ces associations, "openai", "écrire", "étudiants" se démarquent avec des pourcentages élevés de co-occurrence. De plus ces termes ont une p-value très proche de 0 renforçant la validité de ces associations.
#Donc, on peut remarquer que dans le corpus, chatGPT est associé 29 fois à l'entreprise qui est derrière ce modèle d'IA.
#Il est aussi très intéressant de noter les considération au niveau de l'éducation avec des associations comme "professeurs" (8 fois) et étudiants (14 fois).
cooc_terms(dtm2, "données")
#Les données sont donc associées principalement à la scientifique Marianne (7) Bellotti (23). Également dans les décisions.
#À mettre avec la 1ère analyse : D'un autre côté, des termes tels comme "décision", "dit", "type", présentent des pourcentages plus modestes de co-occurrence avec "chatgpt", suggérant une association moins fréquente dans le contexte documentaire.
cooc_terms(dtm2, "intelligence")
#La première chose qui nous frappe c'est qu'"intelligence" est automatiquement associé à "artificielle". Donc, on peut lier ces deux mots qui sont tous deux dans les 10 mots les plus fréquents.
#Ce mot est majoritairement associé avec d'autres mots présentant un système, un chatbot, l'informatique.
#La notion de "danger", "sens", "comprendre" sont également régulièrement associés avec l'intelligence artificielle.
dtm_racine2<-build_dtm(corpus_racine2)
cooc_terms(dtm_racine2, "intelligence")
#Pour la suite de notre analyse, nous allons passer sur les corpus racinisés afin d'éviter les mots avec des pluriels comme donnée et données ou bien décisions ou décision.
#Nous pouvons résumer les associations les plus fréquentes comme cela
terms_graph(dtm2, 10, 3)
# Cette visualisation nous permets d'observer d'un coup d'oeil les associations les plus fréquentes selon les mots les plus cités.
cooc_terms(dtm_racine2, "ia")
#Le mot IA est fortement associé aux mots : pensée, hypothèses, qualité, erreurs
#Pour tous ces termes, la p-value est très proche de 0, démontrant une forte association.
#Ce sera très intéressant pour poursuivre notre analyse car ces mots semblent être clés pour la compréhension du corpus.
terms_graph(dtm2, 10, 3)
# Cette visualisation nous permets d'observer d'un coup d'oeil les associations les plus fréquentes selon les mots les plus cités.
cooc_terms(dtm_racine2, "openai")
#Nous retrouvons bien notre association avec ChatGPT et GPT. Il est aussi important de noter qu'openAI n'est jamais associé à la scientifique Mme. Bellotti.
# Les associations des mots les plus fréquents du corpus établies, nous allons à présent composer un sous-corpus pour comprendre davantage le sens de nos textes.
sous_corpus1<-subset_corpus(corpus2, dtm2, c("ia", "chatgpt", "données","intelligence","openai","outil"))
dtm4<-build_dtm(sous_corpus1)
cloud<- word_cloud(dtm4, col=1:10, n=40, min.freq=4)
#Nous visualisons clairement avec ce nuage présentant les mots de notre sous-corpus que les mots les plus présents sont les mêmes que dans le corpus initial.
cooc_terms(dtm4, "ia")
#Les associations et dissociations présentes dans ce sous-corpus pour le mot "ia" sont globalement les mêmes qu'étudiées précédemment.
cooc_terms(dtm4, "chatgpt")
#Une nouvelle fois, nous retrouvons sensiblement les mêmes résultats qu'initialement.


#NB ; ici, j'avais réalisé l'analyse textuelle avec explor(acm) qui avait fait planter mon mac
acm<-corpus_ca(sous_corpus1, dtm4)
#NB ; la pomme a encore craqué ... j'avais réalisé la fonction corpus clustering.


#De ce fait, nous allons regarder plus en détail les associations.
findAssocs(dtm4,terms = "ia", corlimit = 0.3)
#"inverse" a un score de 0.64, ce qui suggère une forte association avec "chatgpt".
#Je ne comprends pas le terme "antifragile", nous allons donc observer le contexte de citation
concordances(sous_corpus1, dtm4, "antifrile")
concordances(sous_corpus1, dtmX, "antifrile")
concordances(corpus2, dtmX, "antifrile")
dtmY <-build_dtm(sous_corpus1)
concordances(sous_corpus1, dtmY, "antifrile")
concordances(sous_corpus1, dtmY, "antifragile")
#Ce mot "antifragile" est racinisé avec antifragilité. C'est un type d'IA. Pour se définition, est antifragile ce qui profite des événements inattendus.
#On sait donc qu'il y a un score de 0.57, indiquant également une association significative pour présenter ce modèle d'IA.
findAssocs(dtm4,terms = "chatgpt", corlimit = 0.3)
#Ces valeurs de corrélation positive suggèrent que, dans le corpus analysé, les documents ou textes qui mentionnent "chatgpt" ont tendance à également mentionner les termes "articles" et "contenus".
#Le mot données est fondamental à analyser
findAssocs(dtm4,terms = "données", corlimit = 0.3)
#On remarque différentes associations sur des thèmes variés. Notamment la véracité/ qualité des données (évidentes, exploitable,exact(es),qualité,parfaite,propres,complexe,désirable,quantité)
#La sécurité entourant les données est aussi extrêmement important (attaqué,capturées,cybercriminalité, vulnérables, défense)
#Avec cette analyse, on comprends donc que les données sont à la fois quelque chose de très instructifs mais aussi sensible.
#Un  mot a attiré notre attention. Le mot "outil". Effectivement, avec ce dernier, nous allons pouvoir voir les associations principales !
findAssocs(dtm4,terms = "outil", corlimit = 0.3)
#Pour y voir plus clair, nous allons regarder le contexte de citation.
concordances(sous_corpus1, dtmY, "fonctionnalités")
concordances(sous_corpus1, dtmY, "outil")
concordances(sous_corpus1, dtmY, "analyse")
#Ces associations nous apprenent que le spectre d'action est large. fonctionnalités         analyse,critique,innovation, etc
#Dans les textes, on y apprend que ChatGPT est notamment un  outil qui permet d'augmenter le degré d'analyse des individus.
#Avant de dresser une conclusion, il nous reste à analyser quelques mots directement en rapport avec notre sujet. Pour ce faire, nous allons observer les associations et co-occurences de ces derniers. 
findAssocs(dtm4,terms = "question", corlimit = 0.3)
findAssocs(dtm4,terms = "école", corlimit = 0.3)
findAssocs(dtm4,terms = "avantage", corlimit = 0.3)
findAssocs(dtm4,terms = "école", corlimit = 0.3)
concordances(sous_corpus1, dtmY, "biais")
concordances(sous_corpus1, dtmY, "limites")
concordances(corpus2, dtm2, "limites")


#CCL

#Nous pouvons à présent passer à la conclusion de ce corpus.
#Pour résumer nous avions initialement un corpus se composant de 10 textes.
#Les textes traitent de l'intelligence artificielle générative et présentent différents points de vue et analyses. Nous allons donc mettre en lumière : les avantages, les freins, les biais, les limites et les usages attendus de l’intelligence artificielle générative.

#Les avantages de l'intelligence générative sont notamment sa rapidité (associé à 81% avec avantages), et la capacité à avoir de multiples fonctions. Aussi, les intelligences génératives permettent de générer des appréciations et d'approfondir des sujets. Toujours dans ces avantages, les IA nous permettent d'accéder à une plus grande connaissance.

#Les freins portent sur deux volets principaux au travers de ces textes. La gestion des données et la question de l'éducation.
#Effectivement à l'occasion de notre analyse, nous avons pu remarquer que dans le domaine de l'éducation, notamment avec le mot "école". Nous trouvons des associations avec l'inquiétude, les réponses générées, les stéréotypes, la légitimité.
#Les freins aux niveau de la donnée sont ceux portant sur les attaques de vol de données, la cybercriminalité, le niveau de vulnérabilité et la défense de ses dernières.

#La gestion des biais doit également se poser dans notre conclusion.
#Avec les IA, on a retrouve des inquiétudes quant aux billets politiques, mais aussi les biais en général notamment en ce qui concerne les modélisation.
#Ces biais et les inquiétudes concernant la sécurité des données et le rôle dans l'éducations constituent les premières limites de l'IA générative.
#La réelle sémantique des mots semble encore échapper aux IA génératives. De plus la gestion de la donnée et du Big Data posent aussi une limite.
#La conformité à la réglementation européenne pose aussi une limite de l'IA générative. Par exemple, ChatGPT est une entreprise américaine.
#Finalement, les usages principaux de l'IA générative ont bien étés mis en avant lors de notre analyse du sous-corpus
#Les IA génératives sont employées pour effectuer des analyses complètes de sites web. Elles excellent aussi dans la traduction automatique de langues et sont donc utilisées à des fins de traduction.
Les IA génératives peuvent être utilisées par les graphistes et les architectes pour générer des images.
#Elles peuvent être utilisées par les graphistes et les architectes pour générer des images.
#Les IA génératives sont utilisées également par certains romantiques 2.0 pour conquérir le coeur de leurs dulcinée. Notamment en générant des poèmes.
#Une autre utilisation atypique est le fait de générer des deepfakes. Bien que cela soulève des questions éthiques, cette technologie peut également être utilisée à des fins artistiques et créatives.
#Enfin en ce qui concerne une utilisation plus professionnelles, les IA génératives sont utilisées pour générer automatiquement du contenu écrit. Par exemple, on sait que nous pouvons les utiliser pour la création de rapports, d'articles de blog, ou d'autres formes de rédaction. Des algorithmes peuvent aussi être générés.


#Au final les IAG et ChatGPT représentent une avancée majeure dans de nombreux domaines comme la santé, la science, la littérature, le marketing, la communication, l'économie. Les possibilités d'avancées dans ses domaines sont démultipliée avec les IAG, toutefois de nombreuses limites viennent se greffer à cette innovation majeure.
